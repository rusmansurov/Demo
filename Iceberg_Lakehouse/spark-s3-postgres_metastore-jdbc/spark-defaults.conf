spark.master=spark://spark-master:7077

# Iceberg Catalog
spark.sql.catalog.iceberg_catalog=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg_catalog.catalog-impl=org.apache.iceberg.jdbc.JdbcCatalog
spark.sql.catalog.iceberg_catalog.uri=jdbc:postgresql://metastore:5432/metastore_db
spark.sql.catalog.iceberg_catalog.jdbc.user=iceberg
spark.sql.catalog.iceberg_catalog.jdbc.password=iceberg
spark.sql.defaultCatalog=iceberg_catalog
spark.sql.catalog.iceberg_catalog.warehouse=s3a://dlh/
spark.sql.catalog.iceberg_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.iceberg_catalog.s3.endpoint=http://minio:9000
spark.sql.catalog.iceberg_catalog.s3.region=us-east-1
spark.sql.catalog.iceberg_catalog.s3.path-style-access=true

# Enable Iceberg SQL support
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# Spark fallback (S3A)
spark.hadoop.fs.s3a.access.key=lakehouseuser
spark.hadoop.fs.s3a.secret.key=lakehousepass
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.connection.ssl.enabled=false

# Force AWS credentials and region for SDK v2 (Iceberg S3FileIO)
spark.driver.extraJavaOptions=-Daws.region=us-east-1 -Daws.accessKeyId=lakehouseuser -Daws.secretAccessKey=lakehousepass
spark.executor.extraJavaOptions=-Daws.region=us-east-1 -Daws.accessKeyId=lakehouseuser -Daws.secretAccessKey=lakehousepass

# Spark UI logs
spark.eventLog.enabled=true
spark.eventLog.dir=file:/opt/spark/logs
spark.history.fs.logDirectory=file:/opt/spark/logs
spark.history.ui.port=18080
